# ì°¸ê³ : https://yogyui.tistory.com/entry/%EA%B8%88%EC%9C%B5%EA%B0%90%EB%8F%85%EC%9B%90OPENDART-%EC%A0%84%EC%9E%90%EA%B3%B5%EC%8B%9C-Open-API-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0
from bs4 import BeautifulSoup


# 1. ì£¼ì£¼ì´íšŒì†Œì§‘ê³µê³  ê³µì‹œë³´ê³ ì„œ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
def collect_statement_list(start_date, end_date,pblntf_detail_ty):
    """íŠ¹ì • ì¡°ê±´ì— ë§ëŠ” ê³µì‹œë³´ê³ ì„œ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ë§¤ì„œë“œ"""

    url = 'https://opendart.fss.or.kr/api/list.json'

    # ë¹ˆ df ìƒì„±(APIë¡œ ë¶ˆëŸ¬ì™€ì§€ëŠ” ë°ì´í„°ì— ë§ê²Œ ë¯¸ë¦¬ ì •ì˜ í•„ìš”)
    res_df = pd.DataFrame(columns = ['corp_code', 'corp_name', 'stock_code'
                                , 'corp_cls', 'report_nm','rcept_no'
                                , 'flr_nm', 'rcept_dt', 'rm'])
    page_no = 1
    while True:
        params = {"crtfc_key": api_key,
            "bgn_de":   start_date,
            "end_de": end_date,
            "pblntf_detail_ty": pblntf_detail_ty,
            "page_no": page_no,
            "page_count": '100'}

        res = requests.get(url, params=params) # API í˜¸ì¶œ
        data = res.json()   # ë¶ˆëŸ¬ì˜¨ json to dictionary ë³€í™˜


        if data['page_no'] != page_no:
            print("í˜ì´ì§€ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤, ì¡°íšŒí•œ í˜ì´ì§€: ",data['page_no'],"!= param page_no: ",page_no)
            break

        # if data['message'] == 'ì¡°íšŒëœ ë°ì´íƒ€ê°€ ì—†ìŠµë‹ˆë‹¤.': #ë°ì´íƒ€ ã…
        #     continue

        try:
            new_data = pd.DataFrame(data["list"]) # dictionary to df ë³€í™˜
            res_df = pd.concat([res_df, new_data], ignore_index=True)
        except Exception as e:
            print("ì—ëŸ¬ ë°œìƒ: ",e, "ì—ëŸ¬ ë°œìƒ êµ¬ì—­ì˜ ê³ ìœ ë²ˆí˜¸: ",corp_code)

        page_no += 1

    print("ì •ê¸° ë³´ê³ ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ì‘ì—… ì™„ë£Œ----------------------------------")
    #
    res_df["report_nm"] = res_df["report_nm"].str.replace(r"\[.*?\]|\(.*?\)", "", regex=True).str.strip()
    return res_df

# ì£¼ì£¼ì´íšŒì†Œì§‘ê³µê³  ìˆ˜ì§‘
rep_df = collect_statement_list(start_date='20250314',end_date='20250317',pblntf_detail_ty='E006')

# 500ëŒ€ ê¸°ì—…ì˜ ë³´ê³ ì„œì¸ì§€ ì²´í¬
def is_500comp(corp_code):
    com500_df = pd.read_excel('2024ë…„ ê¸°ì¤€ 500ëŒ€ ê¸°ì—…(ê³ ìœ ë²ˆí˜¸ ë° ì¢…ëª©ì½”ë“œ í¬í•¨).xlsx',
                              dtype={"ìˆœìœ„": int,
                                     "ì¢…ëª©ì½”ë“œ": str,
                                     "ê³ ìœ ë²ˆí˜¸": str})

    if str(corp_code) in list(com500_df['ê³ ìœ ë²ˆí˜¸']):
        return "â—"
    else:
        return ""


rep_df['500comp'] = rep_df['corp_code'].apply(is_500comp)
rep_df = rep_df[rep_df['500comp']=="â—"] # 500ëŒ€ ê¸°ì—…ì˜ ë³´ê³ ì„œ ë°œí‘œ ì •ë³´ë§Œ ë‚¨ê¸°ê¸°

# 2. ë³´ê³ ì„œ ì›ë³¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
def save_statement_report(rcept_no):
    """ë””ë ‰í† ë¦¬ ë‚´ ê³µì‹œë³´ê³ ì„œ ì›ë³¸íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ë§¤ì„œë“œ"""

    # ê³µì‹œë³´ê³ ì„œ ì›ë³¸ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” API
    # ë°˜í™˜ ê²°ê³¼ = zip file í¬ë§·ì˜ ë°”ì´ë„ˆë¦¬ íŒŒì¼(xml)
    url = 'https://opendart.fss.or.kr/api/document.xml'

    # ê³µì‹œë³´ê³ ì„œì˜ ê³ ìœ  ì ‘ìˆ˜ë²ˆí˜¸ë¥¼ inputìœ¼ë¡œ ë„£ì–´ì¤˜ì•¼í•¨
    params = {"crtfc_key": api_key, "rcept_no": rcept_no}


    # íŒŒì¼ ì €ì¥ ê²½ë¡œ(ë””ë ‰í† ë¦¬) ì§€ì •
    doc_zip_path = os.path.abspath(f'./{rcept_no}.zip')

    if not os.path.isfile(doc_zip_path):
        res = requests.get(url, params=params)

        with open(doc_zip_path, 'wb') as f: # ë°”ì´ë„ˆë¦¬ ëª¨ë“œ = wb
            f.write(res.content)

    zf = ZipFile(doc_zip_path)  # zip íŒŒì¼ì—´ê¸°
    zf.extractall()             # ë””ë ‰í† ë¦¬ ë‚´ zip ì••ì¶• í•´ì œ


    # íŒŒì¼ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸°
    zipinfo = zf.infolist()
    filenames = [x.filename for x in zipinfo]
    filename = filenames[0]

    # ì••ì¶• íŒŒì¼ ë‹«ê¸°
    zf.close()

    # ë””ë ‰í† ë¦¬ ë‚´ zip íŒŒì¼ ì§€ìš°ê¸°
    os.remove(doc_zip_path)
    print(rcept_no,"ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


for rcept_no in rep_df['rcept_no']:
    save_statement_report(rcept_no)

# 3. ìœ„ì›íšŒ ê´€ë ¨ xml ë‚´ tableë¥¼ dfë¡œ ë§Œë“¤ê¸°
def read_statement_report():
    # ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    with open(filename, "r", encoding="utf-8") as file:
        xml_content = file.read()

    # BeautifulSoupìœ¼ë¡œ XML íŒŒì‹±
    soup = BeautifulSoup(xml_content, 'xml')

    # 'ì´ì‚¬íšŒë‚´ ìœ„ì›íšŒ'ê°€ í¬í•¨ëœ ì œëª© ì°¾ê¸°
    # ğŸ“Œ ì´í›„ì— 'ìœ„ì›íšŒ'ì™€ 'í™œë™ë‚´ì—­'ì´ ì¡´ì¬í•˜ëŠ” ì œëª© ì°¾ê¸°ë¡œ ë¦¬íŒ©í† ë§
    target_title = None
    for title in soup.find_all("TITLE"):
        if 'ì´ì‚¬íšŒë‚´ ìœ„ì›íšŒ' in title.text:
            target_title = title
            break  # ì²« ë²ˆì§¸ë¡œ ì°¾ì€ ê²ƒì„ ì‚¬ìš©

    # ì œëª© ë°”ë¡œ ì•„ë˜ì— ìˆëŠ” table
    target_table = None
    if target_title:
        next_sibling = target_title.find_next_sibling("TABLE")
        if next_sibling:
            target_table = next_sibling

    # í…Œì´ë¸”ì´ ì¡´ì¬í•  ë•Œë§Œ ë³€í™˜
    if target_table:
        rows = target_table.find_all("TR")  # ëª¨ë“  <TR> íƒœê·¸ ì°¾ê¸°
        table_data = [[col.get_text(strip=True) for col in row.find_all(["TH", "TD"])] for row in rows]

        # Pandas DataFrame ìƒì„±
        df = pd.DataFrame(table_data)

        # ì¶œë ¥
        print(df)